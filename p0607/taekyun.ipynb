{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/anantSinghCross/xray_classification_pneumonia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "base_path = './xray_classification_pneumonia/Dataset_compressed/train'\n",
    "file_path = list(glob.glob(base_path + \"/*/*.*\"))\n",
    "pneumonia = list(glob.glob(base_path+\"/PNEUMONIA/*.*\"))\n",
    "normal = list(glob.glob(base_path+\"/NORMAL/*.*\"))\n",
    "\n",
    "# pneumonia\n",
    "# normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3875, 1341)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pneumonia), len(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./xray_classification_pneumonia/Dataset_compressed/train\\\\NORMAL\\\\0.jpg',\n",
       " './xray_classification_pneumonia/Dataset_compressed/train\\\\NORMAL\\\\1.jpg',\n",
       " './xray_classification_pneumonia/Dataset_compressed/train\\\\NORMAL\\\\10.jpg',\n",
       " './xray_classification_pneumonia/Dataset_compressed/train\\\\NORMAL\\\\100.jpg',\n",
       " './xray_classification_pneumonia/Dataset_compressed/train\\\\NORMAL\\\\1000.jpg']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./xray_classification_pneumonia/Dataset_compressed/train\\NORMAL\n",
      "('./xray_classification_pneumonia/Dataset_compressed', 'train')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "test = os.path.dirname(file_path[0])\n",
    "print(test)\n",
    "class_name = os.path.split(os.path.dirname(test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name to label\n",
    "labels = []\n",
    "for fp in file_path:\n",
    "    tmp = os.path.dirname(fp)\n",
    "    class_name = os.path.split(tmp)\n",
    "    if class_name[1] == \"PNEUMONIA\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "3250 images to array\n",
      "3500 images to array\n",
      "3750 images to array\n",
      "4000 images to array\n",
      "4250 images to array\n",
      "4500 images to array\n",
      "4750 images to array\n",
      "5000 images to array\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import cv2\n",
    "img_width = 60\n",
    "img_height = 60\n",
    "dataset = np.ndarray(shape=(len(file_path), img_height*img_width), dtype=np.float32)\n",
    "i=0\n",
    "for _file in file_path:\n",
    "    img = cv2.imread(_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    dataset[i] = img_resized.flatten()\n",
    "    i += 1\n",
    "    if i % 250 == 0:\n",
    "        print(f\"{i} images to array\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(dataset, labels, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4172, 1044, 4172, 1044)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test = map(lambda x: to_categorical(x),[y_train,y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 100)               360100    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 365,252\n",
      "Trainable params: 365,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,activation='relu',input_shape=(3600,)))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 736us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.0589401e-13, 1.0000000e+00],\n",
       "       [1.0000000e+00, 1.6675341e-28],\n",
       "       [1.0000000e+00, 1.7295543e-21],\n",
       "       ...,\n",
       "       [9.9996912e-01, 3.0827970e-05],\n",
       "       [1.0000000e+00, 2.7162708e-30],\n",
       "       [1.0000000e+00, 6.8399528e-34]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 41.2651 - accuracy: 0.7963 - val_loss: 2.4131 - val_accuracy: 0.9291\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.8264 - accuracy: 0.8869 - val_loss: 31.7417 - val_accuracy: 0.5421\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 11.5515 - accuracy: 0.8456 - val_loss: 3.5159 - val_accuracy: 0.9444\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5151 - accuracy: 0.9425 - val_loss: 3.7618 - val_accuracy: 0.9262\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.1614 - accuracy: 0.9264 - val_loss: 3.9266 - val_accuracy: 0.9176\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1091 - accuracy: 0.9437 - val_loss: 2.1306 - val_accuracy: 0.9521\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.2650 - accuracy: 0.9377 - val_loss: 7.2030 - val_accuracy: 0.8630\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.8713 - accuracy: 0.9142 - val_loss: 3.3282 - val_accuracy: 0.9377\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8359 - accuracy: 0.9501 - val_loss: 2.0304 - val_accuracy: 0.9511\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.5008 - accuracy: 0.9173 - val_loss: 2.2346 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.7638 - accuracy: 0.9492 - val_loss: 1.9392 - val_accuracy: 0.9531\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7751 - accuracy: 0.9463 - val_loss: 5.5150 - val_accuracy: 0.8688\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.9621 - accuracy: 0.9255 - val_loss: 8.0349 - val_accuracy: 0.8649\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.3942 - accuracy: 0.9250 - val_loss: 3.7216 - val_accuracy: 0.9119\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7209 - accuracy: 0.9516 - val_loss: 1.9438 - val_accuracy: 0.9464\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9040 - accuracy: 0.9406 - val_loss: 1.7415 - val_accuracy: 0.9492\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.9394 - val_loss: 1.5888 - val_accuracy: 0.9531\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.9687 - accuracy: 0.9621 - val_loss: 1.4634 - val_accuracy: 0.9511\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9397 - accuracy: 0.9358 - val_loss: 1.6370 - val_accuracy: 0.9531\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2611 - accuracy: 0.9542 - val_loss: 1.3311 - val_accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "model_adam = build()\n",
    "model_adam.compile(optimizer=optimizers.Adam(learning_rate = 0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model_adam.fit(x_train,y_train, validation_data=(x_test,y_test), batch_size=64,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 753us/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "prediction = model_adam.predict(x_test)\n",
    "prediction_class = np.argmax(prediction,axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
